{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAlex API Webinar - Tutorial 01\n",
    "April 25, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Jupyter Notebook accompanying the first OpenAlex webinar on using Python to access the API.\n",
    "\n",
    "* If you aren't familiar with Jupyter notebooks, [you can learn more here](https://jupyter.org/try-jupyter/notebooks/?path=notebooks/Intro.ipynb)\n",
    "* To learn all about the OpenAlex API: [visit the technical documentation](https://docs.openalex.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAlex API is very powerful, but it is also very easy to use. There is no authentication required, and all your code needs to do is make standard HTTP GET requests.\n",
    "\n",
    "While there are some good libraries you can use to access the API, we're going to start very simply by making API calls directly. We will import just two small libraries to help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup: import libraries\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Alert\n",
    "# IMPORTANT: Set your email here in order to use the API's \"polite pool\"\n",
    "# See: https://docs.openalex.org/how-to-use-the-api/rate-limits-and-authentication#the-polite-pool\n",
    "mailto = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openalex.org/works\"\n",
    "if not mailto:\n",
    "    raise ValueError(\"You need to fill in your email address in the `mailto` variable above!\")\n",
    "params = {\n",
    "    \"mailto\": \"jportenoy@ourresearch.org\",\n",
    "    \"filter\": \"authorships.author.id:a5086928770\",  # Kyle Demes's author ID\n",
    "    \"per-page\": 100,\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# A \"200\" status code means that the API query was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 24\n"
     ]
    }
   ],
   "source": [
    "results = response.json()['results']\n",
    "print(f\"Number of results: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kdemes_works.csv', 'w', newline='') as f:\n",
    "    # initialize the csv writer for this file\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a header row at the top\n",
    "    header = ['id', 'doi', 'publication_year', 'title']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # loop through the works and write each row\n",
    "    for item in results:\n",
    "        this_id = item['id']\n",
    "        this_doi = item['doi']\n",
    "        this_publication_year = item['publication_year']\n",
    "        this_title = item['title']\n",
    "        writer.writerow([this_id, this_doi, this_publication_year, this_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University (Institution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done paging through results. We made 44 API queries, and retrieved 4248 results.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openalex.org/works\"\n",
    "params = {\n",
    "    \"mailto\": \"jportenoy@ourresearch.org\",\n",
    "    \"filter\": f\"authorships.institutions.lineage:i129801699,publication_year:>2022\",  # University of Tasmania\n",
    "    \"per-page\": 100,\n",
    "    \"select\": \"id,doi,publication_year,title\",\n",
    "}\n",
    "\n",
    "# Initialize cursor\n",
    "cursor = \"*\"\n",
    "\n",
    "# Loop through pages\n",
    "all_results = []\n",
    "count_api_queries = 0\n",
    "while cursor:\n",
    "    params[\"cursor\"] = cursor\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Oh no! Something went wrong during the live demo! How embarrassing!\")\n",
    "        break\n",
    "    this_page_results = response.json()['results']\n",
    "    for result in this_page_results:\n",
    "        all_results.append(result)\n",
    "    count_api_queries += 1\n",
    "\n",
    "    # Update cursor\n",
    "    cursor = response.json()['meta']['next_cursor']\n",
    "print(f\"Done paging through results. We made {count_api_queries} API queries, and retrieved {len(all_results)} results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make our cursor paging code above into a function, so we can reuse it easily\n",
    "def api_query_page_results(url, params):\n",
    "    # Initialize cursor\n",
    "    cursor = \"*\"\n",
    "\n",
    "    # Loop through pages\n",
    "    all_results = []\n",
    "    while cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Oh no! Something went wrong during the live demo! How embarrassing!\")\n",
    "            response.raise_for_status()\n",
    "        this_page_results = response.json()['results']\n",
    "        for result in this_page_results:\n",
    "            all_results.append(result)\n",
    "\n",
    "        # Update cursor\n",
    "        cursor = response.json()['meta']['next_cursor']\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done collecting references. We retrieved 9237 works.\n"
     ]
    }
   ],
   "source": [
    "# collect all of the works referenced by the works found above\n",
    "# This will be a dictionary mapping Citing Paper -> List of Cited Papers\n",
    "all_references = {}\n",
    "\n",
    "# Let's limit the results to loop through to only n=100, because this is a demo, and we don't want to wait for too long\n",
    "works_to_collect = all_results[:100]\n",
    "\n",
    "# We will keep track of the number of works retrieved from the API\n",
    "count_works_retrieved = 0\n",
    "\n",
    "for work in works_to_collect:\n",
    "    # Get references to this work (i.e., works that have been cited by this work)\n",
    "    this_work_id = work['id']\n",
    "    url = \"https://api.openalex.org/works\"\n",
    "    params = {\n",
    "        \"mailto\": \"jportenoy@ourresearch.org\",\n",
    "        \"filter\": f\"cited_by:{this_work_id}\",\n",
    "        \"per-page\": 100,\n",
    "        \"select\": \"id,doi,publication_year,title, primary_location, authorships, topics\",\n",
    "    }\n",
    "    this_work_references = api_query_page_results(url, params=params)\n",
    "    # put this data into our dictionary:\n",
    "    all_references[this_work_id] = this_work_references\n",
    "    count_works_retrieved += len(this_work_references)\n",
    "print(f\"Done collecting references. We retrieved {count_works_retrieved} works.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to shorten the OpenAlex ID to make it better for display\n",
    "def make_short_id(long_id):\n",
    "    short_id = long_id.replace(\"https://openalex.org/\", \"\")\n",
    "    return short_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Python documentation shows how to write data to a CSV file:\n",
    "# https://docs.python.org/3/library/csv.html\n",
    "output_filename = \"tasmania_paper_references.csv\"\n",
    "with open(output_filename, 'w', newline='') as f:\n",
    "    # initialize the csv writer for this file\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a header row at the top\n",
    "    header = ['citing_paper_id', 'cited_paper_id']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # loop through each citation, writing one row for each citation\n",
    "    for citing_id, cited_works in all_references.items():\n",
    "        citing_id_short = make_short_id(citing_id)\n",
    "        for cited_work in cited_works:\n",
    "            cited_id_short = make_short_id(cited_work['id'])\n",
    "            writer.writerow([citing_id_short, cited_id_short])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "citation_counts = Counter()\n",
    "for citing_id, cited_works in all_references.items():\n",
    "    citation_counts.update([w['id'] for w in cited_works])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'https://openalex.org/W4285098544',\n",
       " 'doi': 'https://doi.org/10.1016/j.preteyeres.2022.101110',\n",
       " 'publication_year': 2023,\n",
       " 'title': 'RNA-targeting strategies as a platform for ocular gene therapy'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"tasmania_references_paper_metadata.csv\"\n",
    "seen_work_ids = set()\n",
    "with open(output_filename, 'w', newline='') as f:\n",
    "    # initialize the csv writer for this file\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a header row at the top\n",
    "    header = ['work_id', 'title', 'doi', 'utasmania_citation_count', 'source_id', 'source_display_name', 'primary_topic_id', 'primary_topic_display_name']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for cited_works in all_references.values():\n",
    "        for w in cited_works:\n",
    "            work_id = w['id']\n",
    "            work_id_short = make_short_id(work_id)\n",
    "            title = w['title']\n",
    "            if work_id not in seen_work_ids and title != 'Deleted Work':\n",
    "                # Write a row to the CSV file for this work\n",
    "                primary_location = w['primary_location']\n",
    "                doi = w['doi']\n",
    "                utasmania_citation_count = citation_counts[work_id]\n",
    "\n",
    "                # Get source (journal)\n",
    "                try:\n",
    "                    source = w['primary_location']['source']\n",
    "                    source_id = source['id']\n",
    "                    source_id_short = make_short_id(source_id)\n",
    "                    source_display_name = source['display_name']\n",
    "                except (KeyError, TypeError):\n",
    "                    source_id = None\n",
    "                    source_display_name = None\n",
    "\n",
    "                \n",
    "                # Get primary_topic\n",
    "                try:\n",
    "                    primary_topic = w['topics'][0]\n",
    "                    primary_topic_id = primary_topic['id']\n",
    "                    primary_topic_id_short = make_short_id(primary_topic_id)\n",
    "                    primary_topic_display_name = primary_topic['display_name']\n",
    "                except (IndexError, KeyError, TypeError):\n",
    "                    primary_topic_id = None\n",
    "                    primary_topic_display_name = None\n",
    "                \n",
    "                writer.writerow([work_id_short, title, doi, utasmania_citation_count, source_id_short, source_display_name, primary_topic_id_short, primary_topic_display_name])\n",
    "            \n",
    "                seen_work_ids.add(work_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
